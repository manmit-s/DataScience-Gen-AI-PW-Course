{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1: What is K-Nearest Neighbors (KNN) and how does it work in both classification and regression problems?\n",
        "\n",
        "**Answer:**  \n",
        "K-Nearest Neighbors (KNN) is a non-parametric, instance-based learning algorithm used for classification and regression.  \n",
        "- **Classification:** It assigns a class label based on the majority vote of the k closest data points in the feature space.  \n",
        "- **Regression:** It predicts a continuous value by averaging the target values of the k nearest neighbors.  \n",
        "KNN relies on a distance metric (e.g., Euclidean) to determine proximity and does not require model training, making it simple yet powerful.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 2: What is the Curse of Dimensionality and how does it affect KNN performance?\n",
        "\n",
        "**Answer:**  \n",
        "The Curse of Dimensionality refers to the exponential increase in data sparsity as the number of features grows.  \n",
        "- In high dimensions, all points tend to become equidistant, making it hard for KNN to identify meaningful neighbors.  \n",
        "- It leads to poor generalization, increased computational cost, and reduced accuracy.  \n",
        "Dimensionality reduction techniques like PCA are often used to mitigate this issue.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 3: What is Principal Component Analysis (PCA)? How is it different from feature selection?\n",
        "\n",
        "**Answer:**  \n",
        "PCA is a statistical technique that transforms the original features into a new set of orthogonal components that capture the maximum variance.  \n",
        "- **PCA:** Creates new features (principal components) based on linear combinations of original features.  \n",
        "- **Feature Selection:** Chooses a subset of existing features based on relevance.  \n",
        "PCA is a feature extraction method, while feature selection is about choosing from existing features.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 4: What are eigenvalues and eigenvectors in PCA, and why are they important?\n",
        "\n",
        "**Answer:**  \n",
        "- **Eigenvectors:** Indicate the direction of the new feature axes (principal components).  \n",
        "- **Eigenvalues:** Represent the amount of variance captured by each eigenvector.  \n",
        "In PCA, eigenvectors define the principal components, and eigenvalues help rank them by importance. Selecting components with the highest eigenvalues ensures maximum information retention.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 5: How do KNN and PCA complement each other when applied in a single pipeline?\n",
        "\n",
        "**Answer:**  \n",
        "PCA reduces dimensionality, mitigating the Curse of Dimensionality and noise.  \n",
        "KNN benefits from this by operating in a lower-dimensional space, improving accuracy and efficiency.  \n",
        "Together, they form a robust pipeline:  \n",
        "1. PCA extracts informative features.  \n",
        "2. KNN classifies based on simplified, variance-rich components.  \n",
        "This synergy enhances performance, especially in high-dimensional datasets.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FRXOFFr0-fia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q6: KNN Classifier on Wine Dataset â€“ With and Without Feature Scaling\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load data\n",
        "data = load_wine()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Without scaling\n",
        "knn_raw = KNeighborsClassifier()\n",
        "knn_raw.fit(X_train, y_train)\n",
        "y_pred_raw = knn_raw.predict(X_test)\n",
        "print(\"Accuracy without scaling:\", accuracy_score(y_test, y_pred_raw))\n",
        "\n",
        "# With scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "knn_scaled = KNeighborsClassifier()\n",
        "knn_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = knn_scaled.predict(X_test_scaled)\n",
        "print(\"Accuracy with scaling:\", accuracy_score(y_test, y_pred_scaled))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsJ6Xf7c-jiS",
        "outputId": "90107cdb-b52f-43b5-d67e-1b28f0a6b783"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.7222222222222222\n",
            "Accuracy with scaling: 0.9444444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q7: PCA Explained Variance Ratio\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA()\n",
        "pca.fit(X)\n",
        "\n",
        "# Explained variance ratio\n",
        "print(\"Explained variance ratio of each component:\")\n",
        "print(pca.explained_variance_ratio_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpQhCt2w-0kD",
        "outputId": "f1feed54-de85-4570-a0e2-88b45bfd0ab3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained variance ratio of each component:\n",
            "[9.98091230e-01 1.73591562e-03 9.49589576e-05 5.02173562e-05\n",
            " 1.23636847e-05 8.46213034e-06 2.80681456e-06 1.52308053e-06\n",
            " 1.12783044e-06 7.21415811e-07 3.78060267e-07 2.12013755e-07\n",
            " 8.25392788e-08]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q8: KNN on PCA-transformed data (Top 2 Components)\n",
        "# PCA transform\n",
        "pca_2 = PCA(n_components=2)\n",
        "X_pca = pca_2.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# KNN on PCA data\n",
        "knn_pca = KNeighborsClassifier()\n",
        "knn_pca.fit(X_train_pca, y_train_pca)\n",
        "y_pred_pca = knn_pca.predict(X_test_pca)\n",
        "print(\"Accuracy on PCA-transformed data (2 components):\", accuracy_score(y_test_pca, y_pred_pca))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7Tr9O6H-4vb",
        "outputId": "c248d7ca-0c35-4d98-b8ef-9b4cb4f4883e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on PCA-transformed data (2 components): 0.7222222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q9: KNN with Different Distance Metrics\n",
        "# Euclidean\n",
        "knn_euclidean = KNeighborsClassifier(metric='euclidean')\n",
        "knn_euclidean.fit(X_train_scaled, y_train)\n",
        "y_pred_euclidean = knn_euclidean.predict(X_test_scaled)\n",
        "print(\"Accuracy with Euclidean distance:\", accuracy_score(y_test, y_pred_euclidean))\n",
        "\n",
        "# Manhattan\n",
        "knn_manhattan = KNeighborsClassifier(metric='manhattan')\n",
        "knn_manhattan.fit(X_train_scaled, y_train)\n",
        "y_pred_manhattan = knn_manhattan.predict(X_test_scaled)\n",
        "print(\"Accuracy with Manhattan distance:\", accuracy_score(y_test, y_pred_manhattan))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wTR1Hfx-6zr",
        "outputId": "75bf1dc0-c8c3-4081-9432-c13f1a8f0ba4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Euclidean distance: 0.9444444444444444\n",
            "Accuracy with Manhattan distance: 0.9444444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q10: High-Dimensional Gene Expression Pipeline (Simulated Example)\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Simulate high-dimensional data\n",
        "X_gene, y_gene = make_classification(n_samples=100, n_features=1000, n_informative=50, random_state=42)\n",
        "\n",
        "# Split data\n",
        "X_train_gene, X_test_gene, y_train_gene, y_test_gene = train_test_split(X_gene, y_gene, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale data\n",
        "scaler_gene = StandardScaler()\n",
        "X_train_gene_scaled = scaler_gene.fit_transform(X_train_gene)\n",
        "X_test_gene_scaled = scaler_gene.transform(X_test_gene)\n",
        "\n",
        "# PCA: Keep components explaining 95% variance\n",
        "pca_gene = PCA(n_components=0.95)\n",
        "X_train_gene_pca = pca_gene.fit_transform(X_train_gene_scaled)\n",
        "X_test_gene_pca = pca_gene.transform(X_test_gene_scaled)\n",
        "\n",
        "# KNN classification\n",
        "knn_gene = KNeighborsClassifier()\n",
        "knn_gene.fit(X_train_gene_pca, y_train_gene)\n",
        "y_pred_gene = knn_gene.predict(X_test_gene_pca)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy on gene expression data after PCA:\", accuracy_score(y_test_gene, y_pred_gene))\n",
        "print(\"Number of components retained:\", pca_gene.n_components_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ueWfK0P--CB",
        "outputId": "d8e14903-88c7-488b-ce7c-1a90ee9a9818"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on gene expression data after PCA: 0.65\n",
            "Number of components retained: 73\n"
          ]
        }
      ]
    }
  ]
}