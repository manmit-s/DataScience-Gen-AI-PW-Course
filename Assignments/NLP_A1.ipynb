{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Q1: What is Computational Linguistics and how does it relate to NLP?\n",
        "Computational Linguistics is the interdisciplinary field that studies language using computational methods.  \n",
        "- It combines linguistics, computer science, and AI to model and analyze human language.  \n",
        "- **Relation to NLP:** NLP (Natural Language Processing) is the practical application of computational linguistics.  \n",
        "  - Computational linguistics provides the theory.  \n",
        "  - NLP implements it in real-world systems like chatbots, translation tools, and speech recognition.\n",
        "\n",
        "---\n",
        "\n",
        "## Q2: Historical Evolution of NLP\n",
        "- **1950s–1960s:** Rule-based systems, early machine translation (Georgetown-IBM experiment).  \n",
        "- **1970s–1980s:** Formal grammars, symbolic AI, parsing.  \n",
        "- **1990s:** Statistical methods (Hidden Markov Models, probabilistic approaches).  \n",
        "- **2000s:** Machine learning (SVMs, decision trees).  \n",
        "- **2010s–Present:** Deep learning, word embeddings (Word2Vec, GloVe), transformers (BERT, GPT).\n",
        "\n",
        "---\n",
        "\n",
        "## Q3: Major Use Cases of NLP\n",
        "1. **Chatbots & Virtual Assistants** – Customer support automation (Alexa, Siri, ChatGPT).  \n",
        "2. **Sentiment Analysis** – Understanding customer feedback, reviews, social media posts.  \n",
        "3. **Machine Translation** – Tools like Google Translate for cross-language communication.\n",
        "\n",
        "---\n",
        "\n",
        "## Q4: Text Normalization\n",
        "Text normalization = converting text into a consistent format.  \n",
        "- **Steps:** lowercasing, removing punctuation, expanding contractions, handling special characters.  \n",
        "- **Importance:**  \n",
        "  - Reduces variability in text.  \n",
        "  - Ensures consistent meaning.  \n",
        "  - Improves accuracy in tokenization, sentiment analysis, and ML models.\n",
        "\n",
        "---\n",
        "\n",
        "## Q5: Stemming vs Lemmatization\n",
        "- **Stemming:**  \n",
        "  - Rule-based truncation of word endings.  \n",
        "  - May produce non-dictionary words.  \n",
        "  - Example: *“studies” → “studi”*.  \n",
        "\n",
        "- **Lemmatization:**  \n",
        "  - Uses vocabulary + morphology.  \n",
        "  - Produces valid dictionary words.  \n",
        "  - Example: *“studies” → “study”*.  \n",
        "\n",
        "**Comparison Table:**\n",
        "\n",
        "| Aspect       | Stemming                | Lemmatization             |\n",
        "|--------------|-------------------------|---------------------------|\n",
        "| Approach     | Rule-based truncation   | Dictionary + morphology   |\n",
        "| Output       | May not be valid words  | Always valid words        |\n",
        "| Speed        | Faster                  | Slower                    |\n",
        "| Accuracy     | Lower                   | Higher                    |\n",
        "\n",
        "---\n",
        "\n",
        "## Q10: Workflow for Customer Reviews (Fintech Startup)\n",
        "1. **Data Collection:** Gather reviews from app, website, social media.  \n",
        "2. **Text Cleaning:** Remove HTML tags, emojis, normalize text.  \n",
        "3. **Tokenization:** Split into words/sentences.  \n",
        "4. **Preprocessing:** Stemming/lemmatization, handle negations, POS tagging.  \n",
        "5. **Feature Extraction:** Bag of Words, TF-IDF, embeddings (Word2Vec, BERT).  \n",
        "6. **Sentiment Analysis:** Classify reviews (positive/negative/neutral).  \n",
        "7. **Topic Modeling:** LDA to find recurring themes (fees, support, usability).  \n",
        "8. **Visualization:** Dashboards for sentiment trends, frequent complaints.  \n",
        "9. **Insights & Action:** Share findings with product/customer service teams."
      ],
      "metadata": {
        "id": "om8FJC-KVByq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q6\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "text = \"\"\"Natural Language Processing (NLP) is a field of AI that helps computers understand human language.\n",
        "It is widely used in chatbots, translation, and sentiment analysis.\"\"\"\n",
        "\n",
        "# Sentence Tokenization\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "print(\"Sentence Tokenization:\")\n",
        "print(sentences)\n",
        "\n",
        "# Word Tokenization\n",
        "words = nltk.word_tokenize(text)\n",
        "print(\"\\nWord Tokenization:\")\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJMVcloUVv-u",
        "outputId": "f23fe0b1-5f45-4387-cf94-69c52dc20179"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Tokenization:\n",
            "['Natural Language Processing (NLP) is a field of AI that helps computers understand human language.', 'It is widely used in chatbots, translation, and sentiment analysis.']\n",
            "\n",
            "Word Tokenization:\n",
            "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'field', 'of', 'AI', 'that', 'helps', 'computers', 'understand', 'human', 'language', '.', 'It', 'is', 'widely', 'used', 'in', 'chatbots', ',', 'translation', ',', 'and', 'sentiment', 'analysis', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q7\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # Added to fix the LookupError\n",
        "\n",
        "text = \"NLP is a powerful tool for analyzing human language data.\"\n",
        "\n",
        "# Tokenize words\n",
        "words = nltk.word_tokenize(text)\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "print(\"Original Words:\", words)\n",
        "print(\"Filtered Words (without stopwords):\", filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlJs3_xPVL7V",
        "outputId": "8eefe53e-011f-41ab-f74c-3c3f4fb1cfd5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Words: ['NLP', 'is', 'a', 'powerful', 'tool', 'for', 'analyzing', 'human', 'language', 'data', '.']\n",
            "Filtered Words (without stopwords): ['NLP', 'powerful', 'tool', 'analyzing', 'human', 'language', 'data', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q8\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "words = [\"running\", \"studies\", \"better\", \"flies\"]\n",
        "\n",
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "stems = [stemmer.stem(word) for word in words]\n",
        "\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmas = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "print(\"Original Words:\", words)\n",
        "print(\"Stems:\", stems)\n",
        "print(\"Lemmas:\", lemmas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMHaZW5TVmcG",
        "outputId": "8d59f6e5-aeca-41c7-b758-086b8fcc9417"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Words: ['running', 'studies', 'better', 'flies']\n",
            "Stems: ['run', 'studi', 'better', 'fli']\n",
            "Lemmas: ['running', 'study', 'better', 'fly']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q9\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Sample documents\n",
        "docs = [\n",
        "    \"NLP is a field of artificial intelligence\",\n",
        "    \"Machine learning is used in NLP\",\n",
        "    \"Deep learning has improved NLP performance\"\n",
        "]\n",
        "\n",
        "# Create TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(docs)\n",
        "\n",
        "# Convert to array\n",
        "print(\"TF-IDF Scores:\")\n",
        "print(tfidf_matrix.toarray())\n",
        "\n",
        "# Feature names (words)\n",
        "print(\"\\nFeature Names:\")\n",
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "SDhtqE1EV1Y0",
        "outputId": "4490a1f2-4960-46a8-d5ab-7c7e1695ca11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Scores:\n",
            "[[0.45050407 0.         0.45050407 0.         0.         0.\n",
            "  0.45050407 0.34261996 0.         0.         0.26607496 0.45050407\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.4711101\n",
            "  0.         0.35829137 0.35829137 0.4711101  0.27824521 0.\n",
            "  0.         0.4711101 ]\n",
            " [0.         0.45050407 0.         0.45050407 0.45050407 0.\n",
            "  0.         0.         0.34261996 0.         0.26607496 0.\n",
            "  0.45050407 0.        ]]\n",
            "\n",
            "Feature Names:\n",
            "['artificial' 'deep' 'field' 'has' 'improved' 'in' 'intelligence' 'is'\n",
            " 'learning' 'machine' 'nlp' 'of' 'performance' 'used']\n"
          ]
        }
      ]
    }
  ]
}